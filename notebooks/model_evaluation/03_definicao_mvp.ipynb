{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição do Algoritmo\n",
    "\n",
    "Nesse notebook iremos utilizar as bases de treino que construímos com o auxílio do scrip.py `feature_engineering.py`, presente na pasta `src/feature_engineering/`, para testar diversos algoritmos e identificar qual o melhor a ser utilizado para o problema em questão. Iremos testar desde modelos mais simples como Regressão Logística até os mais complexos como LightGBM e a EBM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from scipy.stats import ks_2samp\n",
    "from utils import *\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "FEATURES = ['faixa_VAR_6', 'faixa_VAR_9', 'faixa_VAR_19', 'faixa_VAR_57', 'faixa_VAR_25', 'faixa_VAR_32', 'faixa_VAR_40', 'faixa_VAR_60', 'grupo_VAR_20']\n",
    "TARGET = 'y'\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_parquet('../../data/interim/treino.parquet')\n",
    "teste = pd.read_parquet('../../data/interim/teste.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando e avaliando Logistic Regression...\n",
      "Treinando e avaliando Decision Tree...\n",
      "Treinando e avaliando Random Forest...\n",
      "Treinando e avaliando Gradient Boosting...\n",
      "Treinando e avaliando LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 2316, number of negative: 5895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40\n",
      "[LightGBM] [Info] Number of data points in the train set: 8211, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.282061 -> initscore=-0.934263\n",
      "[LightGBM] [Info] Start training from score -0.934263\n",
      "Treinando e avaliando Explainable Boosting Machine...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3399f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3399f_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_3399f_level0_col1\" class=\"col_heading level0 col1\" >ROC-AUC Treino</th>\n",
       "      <th id=\"T_3399f_level0_col2\" class=\"col_heading level0 col2\" >ROC-AUC Teste</th>\n",
       "      <th id=\"T_3399f_level0_col3\" class=\"col_heading level0 col3\" >KS Stat Treino</th>\n",
       "      <th id=\"T_3399f_level0_col4\" class=\"col_heading level0 col4\" >KS Stat Teste</th>\n",
       "      <th id=\"T_3399f_level0_col5\" class=\"col_heading level0 col5\" >Accuracy Treino</th>\n",
       "      <th id=\"T_3399f_level0_col6\" class=\"col_heading level0 col6\" >Accuracy Teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3399f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3399f_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_3399f_row0_col1\" class=\"data row0 col1\" >68.82</td>\n",
       "      <td id=\"T_3399f_row0_col2\" class=\"data row0 col2\" >70.12</td>\n",
       "      <td id=\"T_3399f_row0_col3\" class=\"data row0 col3\" >27.95</td>\n",
       "      <td id=\"T_3399f_row0_col4\" class=\"data row0 col4\" >31.66</td>\n",
       "      <td id=\"T_3399f_row0_col5\" class=\"data row0 col5\" >72.32</td>\n",
       "      <td id=\"T_3399f_row0_col6\" class=\"data row0 col6\" >68.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3399f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3399f_row1_col0\" class=\"data row1 col0\" >Decision Tree</td>\n",
       "      <td id=\"T_3399f_row1_col1\" class=\"data row1 col1\" >78.03</td>\n",
       "      <td id=\"T_3399f_row1_col2\" class=\"data row1 col2\" >63.93</td>\n",
       "      <td id=\"T_3399f_row1_col3\" class=\"data row1 col3\" >40.82</td>\n",
       "      <td id=\"T_3399f_row1_col4\" class=\"data row1 col4\" >22.19</td>\n",
       "      <td id=\"T_3399f_row1_col5\" class=\"data row1 col5\" >74.63</td>\n",
       "      <td id=\"T_3399f_row1_col6\" class=\"data row1 col6\" >67.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3399f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3399f_row2_col0\" class=\"data row2 col0\" >Random Forest</td>\n",
       "      <td id=\"T_3399f_row2_col1\" class=\"data row2 col1\" >77.86</td>\n",
       "      <td id=\"T_3399f_row2_col2\" class=\"data row2 col2\" >64.94</td>\n",
       "      <td id=\"T_3399f_row2_col3\" class=\"data row2 col3\" >40.71</td>\n",
       "      <td id=\"T_3399f_row2_col4\" class=\"data row2 col4\" >22.96</td>\n",
       "      <td id=\"T_3399f_row2_col5\" class=\"data row2 col5\" >74.63</td>\n",
       "      <td id=\"T_3399f_row2_col6\" class=\"data row2 col6\" >67.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3399f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3399f_row3_col0\" class=\"data row3 col0\" >Gradient Boosting</td>\n",
       "      <td id=\"T_3399f_row3_col1\" class=\"data row3 col1\" >70.54</td>\n",
       "      <td id=\"T_3399f_row3_col2\" class=\"data row3 col2\" >69.79</td>\n",
       "      <td id=\"T_3399f_row3_col3\" class=\"data row3 col3\" >30.23</td>\n",
       "      <td id=\"T_3399f_row3_col4\" class=\"data row3 col4\" >30.34</td>\n",
       "      <td id=\"T_3399f_row3_col5\" class=\"data row3 col5\" >72.72</td>\n",
       "      <td id=\"T_3399f_row3_col6\" class=\"data row3 col6\" >68.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3399f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3399f_row4_col0\" class=\"data row4 col0\" >LightGBM</td>\n",
       "      <td id=\"T_3399f_row4_col1\" class=\"data row4 col1\" >73.76</td>\n",
       "      <td id=\"T_3399f_row4_col2\" class=\"data row4 col2\" >68.44</td>\n",
       "      <td id=\"T_3399f_row4_col3\" class=\"data row4 col3\" >34.85</td>\n",
       "      <td id=\"T_3399f_row4_col4\" class=\"data row4 col4\" >27.40</td>\n",
       "      <td id=\"T_3399f_row4_col5\" class=\"data row4 col5\" >72.91</td>\n",
       "      <td id=\"T_3399f_row4_col6\" class=\"data row4 col6\" >69.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3399f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3399f_row5_col0\" class=\"data row5 col0\" >Explainable Boosting Machine</td>\n",
       "      <td id=\"T_3399f_row5_col1\" class=\"data row5 col1\" >69.30</td>\n",
       "      <td id=\"T_3399f_row5_col2\" class=\"data row5 col2\" >70.36</td>\n",
       "      <td id=\"T_3399f_row5_col3\" class=\"data row5 col3\" >28.30</td>\n",
       "      <td id=\"T_3399f_row5_col4\" class=\"data row5 col4\" >31.95</td>\n",
       "      <td id=\"T_3399f_row5_col5\" class=\"data row5 col5\" >72.37</td>\n",
       "      <td id=\"T_3399f_row5_col6\" class=\"data row5 col6\" >68.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x147a63f40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos treinar diversos modelos para depois comparar a suas performances\n",
    "results = []\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42),\n",
    "    'Explainable Boosting Machine': ExplainableBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Treinando e avaliando {name}...\")\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model = clf.fit(treino[FEATURES],treino[TARGET])\n",
    "    y_train = treino[TARGET].values.flatten()\n",
    "    y_test = teste[TARGET].values.flatten()\n",
    "\n",
    "    # Gerar predições treino\n",
    "    y_pred_treino = model.predict(treino[FEATURES])\n",
    "    y_pred_proba_treino = model.predict_proba(treino[FEATURES])[:, 1]\n",
    "\n",
    "    # Gerar predições teste \n",
    "    y_pred_teste = model.predict(teste[FEATURES])\n",
    "    y_pred_proba_teste = model.predict_proba(teste[FEATURES])[:, 1]\n",
    "    \n",
    "    # Calcular ROC-AUC\n",
    "    roc_auc_treino = roc_auc_score(treino[TARGET], y_pred_proba_treino)\n",
    "    roc_auc_teste = roc_auc_score(teste[TARGET], y_pred_proba_teste)\n",
    "    \n",
    "    # Calcular Acurácia\n",
    "    accuracy_treino = accuracy_score(treino[TARGET], y_pred_treino)\n",
    "    accuracy_teste = accuracy_score(teste[TARGET], y_pred_teste)\n",
    "    \n",
    "    # Calcular KS\n",
    "    ks_treino = calculate_ks(y_train, y_pred_proba_treino)\n",
    "    ks_teste = calculate_ks(y_test, y_pred_proba_teste)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    results.append({\n",
    "        'Classifier': name,\n",
    "        'ROC-AUC Treino': roc_auc_treino*100,\n",
    "        'ROC-AUC Teste': roc_auc_teste*100,\n",
    "        'KS Stat Treino': ks_treino*100,\n",
    "        'KS Stat Teste': ks_teste*100,\n",
    "        'Accuracy Treino': accuracy_treino*100,\n",
    "        'Accuracy Teste': accuracy_teste*100\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.style.format({\n",
    "        \"ROC-AUC Treino\": \"{:,.2f}\",\n",
    "        \"ROC-AUC Teste\": \"{:,.2f}\",\n",
    "        \"KS Stat Treino\": \"{:,.2f}\",\n",
    "        \"KS Stat Teste\": \"{:,.2f}\",\n",
    "        \"Accuracy Treino\": \"{:,.2f}\",\n",
    "        \"Accuracy Teste\": \"{:,.2f}\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão \n",
    "* É possível de utilizar diferentes tipos de modelo para o problema em questão, com a exceção de da Árvore de Decisão e a Random Forest, que apresentaram indícios fortes de Overfitting. \n",
    "* Iremos tunar os hiperparâmetros do Gradient Boosting, LightGBM e da EBM e posteriormente avaliar o melhor modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
